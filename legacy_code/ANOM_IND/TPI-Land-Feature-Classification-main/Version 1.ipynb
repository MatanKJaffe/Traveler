{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7f81f2ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T00:49:27.196039Z",
     "start_time": "2022-03-14T00:49:23.012656Z"
    }
   },
   "outputs": [],
   "source": [
    "\"#!/usr/bin/env python\"\n",
    "#-*- coding: utf-8- -*-\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on\n",
    "#load prerequisite librarys  for running the code \n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely\n",
    "\n",
    "#%matplotlib"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72b0fcdb",
   "metadata": {},
   "source": [
    "\"\"\"algorithm discription:\"\n",
    "[V] add thread pooling\n",
    "[V] add legend dict\n",
    "[V] add prime number multiplication as labels\n",
    "[V] add sliding window import \n",
    "- add vector layer data\n",
    "[V] add sliding window output\n",
    "- add vector layer from labels and querry code.\n",
    "- add visualization function\n",
    "\n",
    "\n",
    "Nice:\n",
    "- test visibility algo.\n",
    "- copy visibility algo from work\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4085b062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:15:43.813880Z",
     "start_time": "2022-03-14T14:15:43.735037Z"
    }
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u03a3' in position 7798: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\site-packages\\pycodestyle_magic.py\u001b[0m in \u001b[0;36mauto_run_pycodestyle\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mauto_run_pycodestyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mpycodestyle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_before_exec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Error before execution: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_before_exec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-122>\u001b[0m in \u001b[0;36mpycodestyle\u001b[1;34m(line, cell, auto)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# Find get_ipython() in the caller's namespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\site-packages\\pycodestyle_magic.py\u001b[0m in \u001b[0;36mpycodestyle\u001b[1;34m(line, cell, auto)\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;31m# save to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'# The %%pycodestyle cell magic was here\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcell\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;31m# make sure it's written\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\tempfile.py\u001b[0m in \u001b[0;36mfunc_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0m_functools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mfunc_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m             \u001b[1;31m# Avoid closing the file as long as the wrapper is alive,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m             \u001b[1;31m# see issue #18879.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u03a3' in position 7798: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "class TPI_Land_Form_Classification:\n",
    "    \"\"\"\n",
    "    Class prefroming automated landform recognition and transposition from raster to vector layers\n",
    "    \"\"\"\n",
    "    def __init__(self , elevation_model = \"\",output_model = \"lf_output.tif\" , TPI_Radius_m_lst = []):\n",
    "        \"\"\"\n",
    "        Base init Function\n",
    "        - TPI_Radius_m_lst: list of tpi values to comput for land feature recognition\n",
    "        - elevation_model: str the directory for the input elevation_modela\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        TODO : add all of these natively t\n",
    "        #!/usr/bin/env python\n",
    "        #-*- coding: utf-8- -*-\n",
    "        import warnings \n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        #load prerequisite librarys  for running the code \n",
    "        from osgeo import gdal\n",
    "        import numpy as np\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import shapely\"\"\"\n",
    "        \n",
    "        self.elevation_model = elevation_model\n",
    "        self.output_model = output_model\n",
    "        self.TPI_Radius_m_lst = TPI_Radius_m_lst\n",
    "        \n",
    "        assert type(TPI_Radius_m_lst) == list , \"Please enter a list of integer values to TPI_Radius_m_lst\"\n",
    "        assert len(elevation_model) > 0 , \"please enter a valid directory string leading to a GeoTiff file\"\n",
    "        \n",
    "    def get_raster_data(self, elevation_model):\n",
    "        \"\"\"\n",
    "        Function returning numpy array from elevation_model along with resolution of said array\n",
    "         - elevation_model: str the directory for the input elevation_model\n",
    "        \"\"\"\n",
    "        #get raster base data\n",
    "        dem_data = gdal.Open(elevation_model)\n",
    "        #set raster data as array\n",
    "        #dem_array = dem_data.GetRasterBand(1).ReadAsArray()\n",
    "        #get the geotransform data from the raster\n",
    "        transform = dem_data.GetGeoTransform()\n",
    "        #get projection data\n",
    "        projection = dem_data.GetProjection()\n",
    "        #get the rasters resolution\n",
    "        resolution = transform[1]\n",
    "        \n",
    "        return projection ,transform, resolution, dem_array\n",
    "    \n",
    "    \n",
    "    def write_output(self, output_model, output_data, original_transform, original_projection):\n",
    "        \"\"\"\n",
    "        Function writing array to GeoTiff file in user specified directory\n",
    "        - output_model: str the directory for the output model\n",
    "        - output_data: numpy array that the user defines\n",
    "        - original_transform: tupel original raster geotransform\n",
    "        - original_projection: tupel original raster projection\n",
    "        \"\"\"\n",
    "        # set driver\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        #set output driver and instance new raster\n",
    "        ds = driver.Create(output_model, output_data.shape[1], output_data.shape[0], 1, gdal.GDT_Float32) \n",
    "        #set new raster metadata by old raster metadata\n",
    "        ds.SetProjection(dem.GetProjection())\n",
    "        ds.SetGeoTransform(dem.GetGeoTransform())\n",
    "        ds.GetRasterBand(1).WriteArray(out)\n",
    "        #remove writen raster from memory\n",
    "        ds.FlushCache()\n",
    "        ds = None\n",
    "        \n",
    "    #with numpy.mean()\n",
    "    def downsample_res_avg(self, array, scale):\n",
    "        \"\"\"\n",
    "        Function downsampling elevation model by input scale value, aggrigating values by average\n",
    "        - array: elevation model as ndarray\n",
    "        - scale: the value by which the user would like to simplify the input array\n",
    "        \"\"\"\n",
    "        original_width = array.shape[1]\n",
    "        original_hight = array.shape[0]\n",
    "\n",
    "        width = int( original_width / scale)\n",
    "        hight = int(original_hight / scale)\n",
    "\n",
    "        resized_array = np.zeros(shape = (hight, width, 3) ,dtype = np.uint8)\n",
    "\n",
    "        for i in range(0, original_hight , scale):\n",
    "            for j in range(0, original_width , scale):\n",
    "                resized_array[int(i/scale)-1 , int(j/scale)-1 ] = np.mean(array[i:(i + scale), j:(j + scale)], axis = (0,1))\n",
    "\n",
    "        return resized_array\n",
    "\n",
    "    \n",
    "    def get_hillshade(self, slope_array, aspect_array, azimuth = \"90\", angle_altitude = 100, ):\n",
    "        \"\"\"\n",
    "        Function hillshade for each cell in input elevation model\n",
    "        - slope_array: elevation model slope values as ndarray\n",
    "        - aspect_array:  elevation model aspect values as ndarray\n",
    "        - azimuth: azimuth direction for hillshade algorithm calculation\n",
    "        - angle_altitude: altitude for angle calculation in hillshade algorithm\n",
    "        \"\"\"\n",
    "        azimuth = 360 - azimuth\n",
    "        azimuth_rad = azimuth *np.pi/180\n",
    "        altitude_rad = angle_altitude*np.pi/180\n",
    "        shade = np.sin(altitude_rad)*np.sin(slope) + np.cos(altitude_rad)*np.cos(slope)*np.cos((azimuth - np.pi/2)  - aspect)\n",
    "        hillshade = 255 * (shaded + 1)/2\n",
    "        return hillshade\n",
    "        \n",
    "\n",
    "    \n",
    "    def get_slope_and_aspect(self,array, in_degrees = True ):\n",
    "        \"\"\"\n",
    "        Function calculating slope and aspect for each cell in input elevation model\n",
    "        - array: elevation model as ndarray\n",
    "        - in_degrees: boolean switch for returning slope values ini degrees or decimals\n",
    "        \"\"\"\n",
    "        x,y = np.gradient(array)\n",
    "        slope = np.pi/2 - np.arctan(np.sqrt(x*x + y*y))\n",
    "        aspect = np.arctan2(-x,y)\n",
    "        if in_degrees is True:\n",
    "            slope = np.degrees(np.arctan(slope))\n",
    "        return slope, aspect\n",
    "    \n",
    "    def view (self, offset_y, offset_x, shape, step = 1):\n",
    "        \"\"\"\n",
    "        Function returning two matching numpy views for moving window routines.\n",
    "        - 'offset_y' and 'offset_x' refer to the shift in relation to the analysed (central) cell \n",
    "        - 'shape' are 2 dimensions of the data matrix (not of the window!)\n",
    "        - 'view_in' is the shifted view and 'view_out' is the position of central cells\n",
    "        \"\"\"\n",
    "        size_y, size_x = shape\n",
    "        x, y = abs(offset_x), abs(offset_y)\n",
    "\n",
    "        x_in = slice(x , size_x, step) \n",
    "        x_out = slice(0, size_x - x, step)\n",
    "\n",
    "        y_in = slice(y, size_y, step)\n",
    "        y_out = slice(0, size_y - y, step)\n",
    "\n",
    "        # the swapping trick    \n",
    "        if offset_x < 0: x_in, x_out = x_out, x_in                                 \n",
    "        if offset_y < 0: y_in, y_out = y_out, y_in\n",
    "\n",
    "        # return window view (in) and main view (out)\n",
    "        return np.s_[y_in, x_in], np.s_[y_out, x_out]\n",
    "\n",
    "        \n",
    "    def calculate_TPI(self, dem_array, radius_m, resolution):\n",
    "        \"\"\"\n",
    "        Function calculating TPI value of dem array at input radius \n",
    "        - dem_array: elevation model as numpy array\n",
    "        - radius_m: radius in meters for TPI calculation\n",
    "        - resolution: Resolution of original elevation model\n",
    "        \"\"\"\n",
    "        #radius in pixels\n",
    "        r = int(np.floor(radius_m/resolution))\n",
    "        #instance window\n",
    "        win = np.ones((2* r +1, 2* r +1))\n",
    "        # win = np.array( [    [0, 1, 1, 1, 0]\n",
    "        #                      [1, 1, 1, 1, 1],\n",
    "        #                      [1, 1, 0, 1, 1],\n",
    "        #                      [1, 1, 1, 1, 1],\n",
    "        #                      [0, 1, 1, 1, 0]  ])\n",
    "\n",
    "        # window radius is needed for the function,\n",
    "        # deduce from window size (can be different for height and width…)\n",
    "        r_y, r_x  = win.shape[0]//2, win.shape[1]//2\n",
    "        win[r_y, r_x  ] = 0  # let's remove the central cell \n",
    "\n",
    "        #matrices for temporary data\n",
    "        mx_temp = np.zeros(dem_array.shape)\n",
    "        mx_count = np.zeros(dem_array.shape)\n",
    "\n",
    "        # loop through window and accumulate values\n",
    "        for (y,x), weight in np.ndenumerate(win):\n",
    "\n",
    "            if weight == 0 : continue  #skip zero values !\n",
    "            # determine views to extract data \n",
    "            view_in, view_out = self.view(y - r_y, x - r_x, dem_array.shape)\n",
    "            # using window weights (eg. for a Gaussian function)\n",
    "            mx_temp[view_out] += dem_array[view_in]  * weight\n",
    "\n",
    "           # track the number of neighbours \n",
    "           # (this is used for weighted mean : Σ weights*val / Σ weights)\n",
    "            mx_count[view_out] += weight\n",
    "\n",
    "        # this is TPI (spot height – average neighbourhood height)\n",
    "        out = dem_array - mx_temp / mx_count\n",
    "        #normalize output\n",
    "        out = ((((out - out.mean()) / out.std()) * 100) + 0.5)\n",
    "        return out\n",
    "    \n",
    "    class Primes():\n",
    "        \"\"\"\n",
    "        class\n",
    "        \"\"\"\n",
    "        math = __import__('math')\n",
    "        def __init__(self,listLength = int):\n",
    "            \"\"\"\n",
    "            func\n",
    "            \"\"\"\n",
    "            assert type(listLength) is int , \"please enter an integer to listLength\"\n",
    "            self.listLength = listLength\n",
    "\n",
    "        def isPrime (self, primeList, candidate):\n",
    "            \"\"\"\n",
    "            func\n",
    "            \"\"\"\n",
    "            upperLimit = self.math.sqrt(candidate)\n",
    "            for p in primeList:\n",
    "                if candidate % p == 0:\n",
    "                    return False\n",
    "                if p >= upperLimit:\n",
    "                    break\n",
    "\n",
    "            return True\n",
    "\n",
    "        def primeList(self):\n",
    "            \"\"\"\n",
    "            func\n",
    "            \"\"\"\n",
    "            if self.listLength < 1 :\n",
    "                return []\n",
    "            primes = [2]\n",
    "\n",
    "            candidate = 3\n",
    "            while self.listLength > len(primes):\n",
    "                if self.isPrime(primes, candidate):\n",
    "                    primes.append(candidate)\n",
    "                candidate +=2\n",
    "\n",
    "            return primes\n",
    "    \n",
    "    def add_prime_labels(self, tpi_array_dict, slope): \n",
    "        tpi_array_lst = list(tpi_array_dict.values()) \n",
    "        primes = self.Primes(listLength= int(4*(len(tpi_array_lst) +1)))\n",
    "        primeList = primes.primeList()\n",
    "\n",
    "        legend_dict = {\"peak\":{\"heirarchy\" : []}, \"valley\" : {\"heirarchy\" : []}, \"slope\" : {\"heirarchy\" : []} , \"plane\": {\"heirarchy\" : []}}\n",
    "\n",
    "        std = tpi_array_lst[-1].std()\n",
    "        lf_array = np.full(tpi_array_lst[-1].shape, 1)\n",
    "\n",
    "        for index, tpi in enumerate(tpi_array_lst):\n",
    "            print(f\"index number {index} started\")\n",
    "            prime1, prime2, prime3, prime4 = primeList[index * 4:(index + 1)* 4]\n",
    "            # add to legend dictionary \n",
    "\n",
    "            lf_array[tpi >= std] = lf_array[tpi > std] * prime4\n",
    "            legend_dict[\"peak\"][\"heirarchy\"].append(prime4)\n",
    "\n",
    "            lf_array[tpi <= -std] = lf_array[tpi < -std] * prime1 \n",
    "            legend_dict[\"valley\"][\"heirarchy\"].append(prime1)\n",
    "\n",
    "            lf_array[(tpi > -std) & (tpi < std ) & (slope >= 6)] = lf_array[(tpi > -std) & (tpi < std ) & (slope >= 6)] * prime2 \n",
    "            legend_dict[\"slope\"][\"heirarchy\"].append(prime2)\n",
    "\n",
    "            lf_array[(tpi > -std) & (tpi < std ) & (slope <= 5)]= lf_array[(tpi > -std) & (tpi < std ) & (slope <= 5)] * prime3\n",
    "            legend_dict[\"plane\"][\"heirarchy\"].append(prime3)\n",
    "\n",
    "            print(f\"index number {index} complete\")\n",
    "        return lf_array ,legend_dict\n",
    "    \n",
    "   \n",
    "    \n",
    "    \"\"\"def visualize(self, array,hillshade):\n",
    "        \n",
    "        Function visualizing the output from the TPI_Land_Form_Classification algorithm\n",
    "        - array: landfrom class labeled array\n",
    "        - hillshade: hillshade claculation output ndarray\n",
    "        \n",
    "        %matplotlib\n",
    "        \n",
    "        # blend hillshade and landform class arrays\n",
    "        blend = array*0.5 + hillshade*0.5\n",
    "        #print array as \n",
    "        plt.imshow(array)\n",
    "        plt.show()\n",
    "        \n",
    "        return\"\"\"\n",
    "    \n",
    "    def test_fit(self):\n",
    "        \"\"\"\n",
    "        Funcution running a mokup of the TPI_Land_Form_Classification algorithm\n",
    "        \"\"\"\n",
    "        #get dem data\n",
    "        #projection ,transform, resolution, dem_array = self.get_raster_data(elevation_model = self.elevation_model)\n",
    "        \n",
    "        #initailize thread pool\n",
    "        \"\"\"from multiprocessing.pool import ThreadPool\n",
    "        from functools import partial\n",
    "        threads = len(self.TPI_Radius_m_lst)\n",
    "        t = ThreadPool(threads)\"\"\"\n",
    "        \n",
    "        # get each array for block by block calculation by the tpi to be run?\n",
    "        # make sure to inlarge it only in the direction where there are values.\n",
    "        # export only from the given window and copy nan values faithfully so as to remove \n",
    "        # unusable data.\n",
    "        # Function to read the raster as arrays for the chosen block size.\n",
    "        \n",
    "        \n",
    "        #get raster base data\n",
    "        ds = gdal.Open(elevation_model)\n",
    "        #get raster and data\n",
    "        band = dem_data.GetRasterBand(1)\n",
    "        # Get \"natural\" block size, and total raster XY size. \n",
    "        block_sizes = band.GetBlockSize()\n",
    "        x_block_size = block_sizes[0]\n",
    "        y_block_size = block_sizes[1]\n",
    "        \"\"\"replace with gcd?\"\"\"\n",
    "        \n",
    "        #add band and array size\n",
    "        xsize = band.XSize\n",
    "        ysize = band.YSize\n",
    "\n",
    "        #get the geotransform data from the raster\n",
    "        geoT = dem_data.GetGeoTransform()\n",
    "        #get projection data\n",
    "        projection = dem_data.GetProjection()\n",
    "        #get the rasters resolution\n",
    "        resolution = geoT[1]\n",
    "\n",
    "        #get projection reference\n",
    "        raster_srs = osr.SpatialReference()\n",
    "        raster_srs.ImportFromWkt(ds.GetProjectionRef())\n",
    "        #----------------------------------------------------------------\n",
    "        #set export data\n",
    "        # set driver\n",
    "        driver = gdal.GetDriverByName('GTiff')\n",
    "        #set output driver and instance new raster\n",
    "        dst_ds = driver.Create(output_model, xsize, ysize, 1, band.DataType) \n",
    "        #set new raster metadata \n",
    "        dst_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "        dst_ds.SetGeoTransform(geoT)\n",
    "\n",
    "\n",
    "        blocks = 0\n",
    "\n",
    "\n",
    "        for y in range(0, ysize, y_block_size):\n",
    "            #print blocks\n",
    "            if y + y_block_size < ysize:\n",
    "                rows = y_block_size\n",
    "            else:\n",
    "                rows = ysize - y\n",
    "            for x in range(0, xsize, x_block_size):\n",
    "                if x + x_block_size < xsize:\n",
    "                    cols = x_block_size\n",
    "                else:\n",
    "                    cols = xsize - x\n",
    "                array = band.ReadAsArray(x, y, cols, rows)\n",
    "\n",
    "                #calculate slope and aspect algorithm\n",
    "                slope_array, aspect_array =  self.get_slope_and_aspect(array = dem_array)\n",
    "\n",
    "                #DO ALGORITHM\n",
    "                #calculate tpi values\n",
    "                \"\"\"add calculation to pad blocks by max tpi value and squize export tif by number of pixels equal to max tpi\"\"\"\n",
    "                \"\"\"do i even need an export raster? i think not! but i should squize the tif by max tpi\"\"\"\n",
    "                tpi_array_dict = {}\n",
    "                for tpi_radius in self.TPI_Radius_m_lst:\n",
    "                    tpi_array_dict[f\"tpi_{tpi_radius}\"] = self.calculate_TPI(dem_array = dem_array, radius_m = tpi_radius ,resolution = resolution)\n",
    "                    \"\"\"#use the threads only to run the tpi algorithm,\n",
    "                    x = t.map(partial(self.calculate_TPI, dem_array = dem_array,resolution = resolution),radius_m = self.TPI_Radius_m_ls)\"\"\"\n",
    "                #export values as sets to dataframe.\n",
    "                \n",
    "\n",
    "                #EXPORT EACH BLOCK INDIVIDUALLY TO EXPORT RASTER\n",
    "                dst_ds.GetRasterBand(1).WriteArray(array, x, y)\n",
    "                del array\n",
    "                blocks += 1\n",
    "        \n",
    "        return lf_array ,legend_dict\n",
    "        \"\"\"\" #calculate slope and aspect algorithm\n",
    "            slope_array, aspect_array =  self.get_slope_and_aspect(array = dem_array)\n",
    "\n",
    "            #calculate tpi values\n",
    "            tpi_array_dict = {}\n",
    "            for tpi_radius in self.TPI_Radius_m_lst:\n",
    "                tpi_array_dict[f\"tpi_{tpi_radius}\"] = self.calculate_TPI(dem_array = dem_array, radius_m = tpi_radius ,resolution = resolution)\n",
    "                use the threads only to run the tpi algorithm,\n",
    "                x = t.map(partial(self.calculate_TPI, dem_array = dem_array,resolution = resolution),radius_m = self.TPI_Radius_m_ls\n",
    "\n",
    "            #calculate landform classes\n",
    "            lf_array ,legend_dict = self.add_prime_labels(tpi_array_dict, slope_array)\n",
    "\n",
    "        \n",
    "        return lf_array ,legend_dict\"\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5469a793",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T00:50:26.334516Z",
     "start_time": "2022-03-14T00:50:04.023440Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:52: E251 unexpected spaces around keyword / parameter equals\n",
      "1:54: E251 unexpected spaces around keyword / parameter equals\n",
      "1:80: E501 line too long (102 > 79 characters)\n",
      "1:92: E251 unexpected spaces around keyword / parameter equals\n",
      "1:94: E251 unexpected spaces around keyword / parameter equals\n",
      "1:98: E231 missing whitespace after ','\n",
      "2:9: E203 whitespace before ','\n",
      "2:10: E231 missing whitespace after ','\n"
     ]
    }
   ],
   "source": [
    "Test = TPI_Land_Form_Classification(elevation_model = \"ALASKA/Alaska.tif\", TPI_Radius_m_lst = [10,20])\n",
    "lf_array ,legend_dict = Test.test_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd7352",
   "metadata": {},
   "source": [
    "# Test Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae7f5ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T17:01:40.272491Z",
     "start_time": "2022-03-13T17:01:40.260483Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"def discrete_matshow(data):\n",
    "    # get discrete colormap\n",
    "    cmap = plt.get_cmap('RdBu', np.max(data) - np.min(data) + 1)\n",
    "    # set limits .5 outside true range\n",
    "    mat = plt.matshow(data, cmap=cmap, vmin=np.min(data) - 0.5, \n",
    "                      vmax=np.max(data) + 0.5)\n",
    "    # tell the colorbar to tick at integers\n",
    "    cax = plt.colorbar(mat, ticks=np.arange(np.min(data), np.max(data) + 1))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e137563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-08T19:29:17.782191Z",
     "start_time": "2022-03-08T19:29:16.512744Z"
    }
   },
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('terrain',len(np.unique(lf_array)))\n",
    "plt.imshow(lf_array, cmap = cmap)\n",
    "plt.title(\"lf_array\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7afb0fbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-13T17:04:26.286130Z",
     "start_time": "2022-03-13T17:04:22.496107Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_88956/131997419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtpi_10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tpi_10.csv\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtpi_30\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tpi_30.csv\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtpi_50\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tpi_50.csv\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtpi_100\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tpi_100.csv\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtpi_300\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tpi_300.csv\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\",\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, like)\u001b[0m\n\u001b[0;32m   2057\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;31m# Parse each line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_line\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfhd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[0mnbvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ox\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tpi_10 = np.genfromtxt(\"tpi_10.csv\" , delimiter= \",\")\n",
    "tpi_30 = np.genfromtxt(\"tpi_30.csv\" , delimiter= \",\")\n",
    "tpi_50 = np.genfromtxt(\"tpi_50.csv\" , delimiter= \",\")\n",
    "tpi_100 = np.genfromtxt(\"tpi_100.csv\" , delimiter= \",\")\n",
    "tpi_300 = np.genfromtxt(\"tpi_300.csv\" , delimiter= \",\")\n",
    "tpi_500 = np.genfromtxt(\"tpi_500.csv\" , delimiter= \",\")\n",
    "\n",
    "slope =  np.genfromtxt(\"slope.csv\" , delimiter= \",\")\n",
    "aspect = np.genfromtxt(\"aspect.csv\" , delimiter= \",\")\n",
    "tpi_array_dict = { \"tpi_10\":tpi_10, \"tpi_30\":tpi_30, \"tpi_50\":tpi_50, \"tpi_100\":tpi_100, \"tpi_300\":tpi_300, \"tpi_500\":tpi_500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get raster base data\n",
    "ds = gdal.Open(elevation_model)\n",
    "#get raster and data\n",
    "band = dem_data.GetRasterBand(1)\n",
    "\n",
    "# Get \"natural\" block size, and total raster XY size. \n",
    "block_sizes = band.GetBlockSize()\n",
    "x_block_size = block_sizes[0]\n",
    "y_block_size = block_sizes[1]\n",
    "\n",
    "#add band and array size\n",
    "xsize = band.XSize\n",
    "ysize = band.YSize\n",
    "\n",
    "#get the geotransform data from the raster\n",
    "geoT = dem_data.GetGeoTransform()\n",
    "#get projection data\n",
    "projection = dem_data.GetProjection()\n",
    "#get the rasters resolution\n",
    "resolution = geoT[1]\n",
    "\n",
    "#get projection reference\n",
    "raster_srs = osr.SpatialReference()\n",
    "raster_srs.ImportFromWkt(ds.GetProjectionRef())\n",
    "#----------------------------------------------------------------\n",
    "#set export data\n",
    "# set driver\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "#set output driver and instance new raster\n",
    "dst_ds = driver.Create(output_model, xsize, ysize, 1, band.DataType) \n",
    "#set new raster metadata \n",
    "dst_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "dst_ds.SetGeoTransform(geoT)\n",
    "\n",
    "\n",
    "blocks = 0\n",
    "    \n",
    "    \n",
    "for y in range(0, ysize, y_block_size):\n",
    "    #print blocks\n",
    "    if y + y_block_size < ysize:\n",
    "        rows = y_block_size\n",
    "    else:\n",
    "        rows = ysize - y\n",
    "    for x in range(0, xsize, x_block_size):\n",
    "        if x + x_block_size < xsize:\n",
    "            cols = x_block_size\n",
    "        else:\n",
    "            cols = xsize - x\n",
    "        array = band.ReadAsArray(x, y, cols, rows)\n",
    "\n",
    "        #DO ALGORITHM\n",
    "        #add calculation that removes empty values and makes sure that each block is the right size.\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        #EXPORT EACH BLOCK INDIVIDUALLY TO EXPORT RASTER\n",
    "        dst_ds.GetRasterBand(1).WriteArray(array, x, y)\n",
    "        del array\n",
    "        blocks += 1\n",
    "\n",
    "#remove writen raster from memory\n",
    "dst_ds.FlushCache()\n",
    "band = None\n",
    "ds = None\n",
    "dst_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "mask = None\n",
    "with rasterio.Env():\n",
    "    with rasterio.open('a_raster') as src:\n",
    "        image = src.read(1) # first band\n",
    "        results = (\n",
    "        {'properties': {'raster_val': v}, 'geometry': s}\n",
    "        for i, (s, v) \n",
    "        in enumerate(\n",
    "            shapes(image, mask=mask, transform=src.transform)))\n",
    "        \n",
    "geoms = list(results)\n",
    "# first feature\n",
    "print( geoms[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dff6de2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-15T13:00:16.345549Z",
     "start_time": "2022-03-15T13:00:15.455731Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'geoms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_88956/678929291.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeometry\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'geometry'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'geoms' is not defined"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import shape\n",
    "shape(geoms[0]['geometry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "499fc833",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T00:54:31.334917Z",
     "start_time": "2022-03-14T00:54:31.278930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:1: E302 expected 2 blank lines, found 0\n",
      "5:1: W293 blank line contains whitespace\n",
      "10:1: W293 blank line contains whitespace\n",
      "13:5: E265 block comment should start with '# '\n",
      "14:21: W291 trailing whitespace\n",
      "20:1: W293 blank line contains whitespace\n",
      "29:13: E265 block comment should start with '# '\n",
      "31:17: E265 block comment should start with '# '\n",
      "33:5: E265 block comment should start with '# '\n"
     ]
    }
   ],
   "source": [
    "from math import gcd\n",
    "# Function to print all the\n",
    "# common divisors\n",
    "def getAllDivisors(arr):\n",
    "    \n",
    "    # Variable to find the gcd\n",
    "    # of N numbers\n",
    "    g = arr[0]\n",
    "    N = len(arr)\n",
    " \n",
    "    # Set to store all the\n",
    "    # common divisors\n",
    "    #divisors = dict()\n",
    "    divisors = set()    \n",
    "    # Finding GCD of the given\n",
    "    # N numbers\n",
    "    print(2)\n",
    "    for i in range(1, N):\n",
    "        g = gcd(arr[i], g)\n",
    "       \n",
    "    # Finding divisors of the\n",
    "    # HCF of n numbers\n",
    "    for i in range(1, g + 1):\n",
    "        if i*i > g:\n",
    "            break\n",
    "            divisors.add(i)\n",
    "        if (g % i == 0):\n",
    "            divisors.add(i)\n",
    "            #divisors[i] = 1\n",
    "            if (g // i != i):\n",
    "                #divisors[g // i] = 1\n",
    "                divisors.add(g // i)\n",
    "    #return set of all devisors\n",
    "    return divisors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "5a760c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:45:18.382081Z",
     "start_time": "2022-03-14T14:45:18.373076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.split(array , 5)\n",
    "getAllDivisors([5846, 2916])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "b7feb5be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:45:22.396467Z",
     "start_time": "2022-03-14T14:45:22.370451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2:68: W291 trailing whitespace\n",
      "3:78: W291 trailing whitespace\n",
      "4:42: W291 trailing whitespace\n",
      "5:42: W291 trailing whitespace\n",
      "6:78: W291 trailing whitespace\n",
      "8:79: W291 trailing whitespace\n",
      "9:80: E501 line too long (108 > 79 characters)\n",
      "9:109: W291 trailing whitespace\n",
      "14:1: E265 block comment should start with '# '\n"
     ]
    }
   ],
   "source": [
    "# shorten array by minimum number of pixels relevant for calculation\n",
    "# ADD TO DOCUMENTATION THAT THERE IS A LOSS OF 2000M ON THE BOUNDRY \n",
    "# OF THE DEM ITERATE OVER BLOCKS TO GET ALL TPI VALUES PERTAINING TO SPECIFIC \n",
    "# MAJOR LANDFORM AND EXPORT THE GEOMETRYS \n",
    "# COULD EVEN DO IT DURING THE CALCULATION \n",
    "# THE MINUTE THE tpi IS CALCULATED FOR LARGEST VALUE EXPORT THE GEOMETRYS AND \n",
    "# UNIFY THE OVERLAPING ONES WITH THE SAME TYPE)\n",
    "# USE POLYGON MASK ON THE TPI ARRAY AND GENERATE THE DIFFRENT HEIRARCHYS UNDER \n",
    "# THIS INDIVIDUAL LANDFORM ALONG WITH THIER GEOMETRY and a hashmap/set of the coordinate values they contain \n",
    "# for quick lookup times.\n",
    "# add overland stuff as properties of smallest polygons\n",
    "# add additional overland stuff properties\n",
    "# save the tiff as a gdal geotiff and lookup the blocksizes\n",
    "# add instance geotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d840c648",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:45:28.923998Z",
     "start_time": "2022-03-14T14:45:28.907989Z"
    }
   },
   "outputs": [],
   "source": [
    "# save each diffrent base landform as an individual shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "489ddaa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T14:45:42.345301Z",
     "start_time": "2022-03-14T14:45:42.298266Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'GetBlockSize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_88956/1633442666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Get \"natural\" block size, and total raster XY size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mblock_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mband\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetBlockSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mx_block_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my_block_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'GetBlockSize'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:1: E265 block comment should start with '# '\n",
      "3:1: E265 block comment should start with '# '\n",
      "5:1: E265 block comment should start with '# '\n",
      "6:1: E265 block comment should start with '# '\n",
      "9:54: W291 trailing whitespace\n",
      "16:1: E265 block comment should start with '# '\n",
      "18:1: E265 block comment should start with '# '\n",
      "20:1: E265 block comment should start with '# '\n"
     ]
    }
   ],
   "source": [
    "#get raster base data\n",
    "dem_data = gdal.Open(\"ALASKA/Alaska.tif\")\n",
    "#get raster and data\n",
    "dem_band = dem_data.GetRasterBand(1)\n",
    "\n",
    "# Get \"natural\" block size, and total raster XY size. \n",
    "block_sizes = band.GetBlockSize()\n",
    "x_block_size = block_sizes[0]\n",
    "y_block_size = block_sizes[1]\n",
    "\n",
    "#add band and array size\n",
    "xsize = band.XSize\n",
    "ysize = band.YSize\n",
    "\n",
    "#get the geotransform data from the raster\n",
    "transform = dem_data.GetGeoTransform()\n",
    "#get projection data\n",
    "projection = dem_data.GetProjection()\n",
    "#get the rasters resolution\n",
    "resolution = transform[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "056e2373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T03:01:14.381430Z",
     "start_time": "2022-03-14T03:01:13.580347Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5:1: E265 block comment should start with '# '\n",
      "11:1: E265 block comment should start with '# '\n",
      "15:5: E225 missing whitespace around operator\n",
      "17:54: W291 trailing whitespace\n",
      "24:1: E265 block comment should start with '# '\n",
      "26:31: E201 whitespace after '('\n",
      "26:38: E202 whitespace before ')'\n",
      "27:77: E202 whitespace before ')'\n",
      "32:1: E265 block comment should start with '# '\n",
      "32:34: W291 trailing whitespace\n",
      "34:1: E302 expected 2 blank lines, found 1\n",
      "42:9: E265 block comment should start with '# '\n",
      "53:13: E265 block comment should start with '# '\n",
      "54:13: E265 block comment should start with '# '\n",
      "55:24: E225 missing whitespace around operator\n",
      "55:27: E225 missing whitespace around operator\n",
      "56:17: E116 unexpected indentation (comment)\n",
      "56:17: E265 block comment should start with '# '\n",
      "57:13: E265 block comment should start with '# '\n",
      "58:17: E116 unexpected indentation (comment)\n",
      "58:17: E265 block comment should start with '# '\n",
      "62:1: E265 block comment should start with '# '\n",
      "64:1: E305 expected 2 blank lines after class or function definition, found 1\n",
      "69:1: E265 block comment should start with '# '\n"
     ]
    }
   ],
   "source": [
    "def read_raster_blocks(x_block_size, y_block_size, elevation_model):\n",
    "    # Function to read the raster as arrays for the chosen block size.\n",
    "    ds = gdal.Open(elevation_model)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    xsize = band.XSize\n",
    "    ysize = band.YSize\n",
    "    blocks = 0\n",
    "    \n",
    "    \n",
    "    for y in range(0, ysize, y_block_size):\n",
    "        #print blocks\n",
    "        if y + y_block_size < ysize:\n",
    "            rows = y_block_size\n",
    "        else:\n",
    "            rows = ysize - y\n",
    "        for x in range(0, xsize, x_block_size):\n",
    "            if x + x_block_size < xsize:\n",
    "                cols = x_block_size\n",
    "            else:\n",
    "                cols = xsize - x\n",
    "            array = band.ReadAsArray(x, y, cols, rows)\n",
    "            \n",
    "            #DO ALGORITHM\n",
    "            \n",
    "            \n",
    "            \n",
    "            #EXPORT EACH BLOCK INDIVIDUALLY TO EXPORT RASTER\n",
    "            dst_ds.GetRasterBand(1).WriteArray(array, x, y)\n",
    "            del array\n",
    "            blocks += 1\n",
    "\n",
    "import numpy\n",
    "from numpy import zeros\n",
    "from numpy import logical_and\n",
    "from osgeo import gdal, osr\n",
    "#import struct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#get raster base data\n",
    "ds = gdal.Open(elevation_model)\n",
    "#get raster and data\n",
    "band = dem_data.GetRasterBand(1)\n",
    "\n",
    "# Get \"natural\" block size, and total raster XY size. \n",
    "block_sizes = band.GetBlockSize()\n",
    "x_block_size = block_sizes[0]\n",
    "y_block_size = block_sizes[1]\n",
    "\n",
    "#add band and array size\n",
    "xsize = band.XSize\n",
    "ysize = band.YSize\n",
    "\n",
    "#get the geotransform data from the raster\n",
    "geoT = dem_data.GetGeoTransform()\n",
    "#get projection data\n",
    "projection = dem_data.GetProjection()\n",
    "#get the rasters resolution\n",
    "resolution = geoT[1]\n",
    "\n",
    "#get projection reference\n",
    "raster_srs = osr.SpatialReference()\n",
    "raster_srs.ImportFromWkt(ds.GetProjectionRef())\n",
    "#----------------------------------------------------------------\n",
    "#set export data\n",
    "# set driver\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "#set output driver and instance new raster\n",
    "dst_ds = driver.Create(output_model, xsize, ysize, 1, band.DataType) \n",
    "#set new raster metadata by old raster metadata\n",
    "dst_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "dst_ds.SetGeoTransform(geoT)\n",
    "\n",
    "\n",
    "blocks = 0\n",
    "    \n",
    "    \n",
    "for y in range(0, ysize, y_block_size):\n",
    "    #print blocks\n",
    "    if y + y_block_size < ysize:\n",
    "        rows = y_block_size\n",
    "    else:\n",
    "        rows = ysize - y\n",
    "    for x in range(0, xsize, x_block_size):\n",
    "        if x + x_block_size < xsize:\n",
    "            cols = x_block_size\n",
    "        else:\n",
    "            cols = xsize - x\n",
    "        array = band.ReadAsArray(x, y, cols, rows)\n",
    "\n",
    "        #DO ALGORITHM\n",
    "\n",
    "\n",
    "\n",
    "        #EXPORT EACH BLOCK INDIVIDUALLY TO EXPORT RASTER\n",
    "        dst_ds.GetRasterBand(1).WriteArray(array, x, y)\n",
    "        del array\n",
    "        blocks += 1\n",
    "\n",
    "#remove writen raster from memory\n",
    "dst_ds.FlushCache()\n",
    "band = None\n",
    "ds = None\n",
    "dst_ds = None\n",
    "\n",
    "dst_ds.GetRasterBand(1).WriteArray(out)\n",
    "#remove writen raster from memory\n",
    "dst_ds.FlushCache()\n",
    "ds = None\n",
    "------------------------------------------\n",
    "#print x_block_size, y_block_size\n",
    "driver = gdal.GetDriverByName( \"GTiff\" )\n",
    "dst_ds = driver.Create(\"output.tif\", xsize, ysize, 1, band.DataType )\n",
    "dst_ds.SetGeoTransform(geoT)\n",
    "dst_ds.SetProjection(raster_srs.ExportToWkt())\n",
    "\n",
    "#print\"working................... \n",
    "# Function to read the raster as arrays for the chosen block size.\n",
    "            \n",
    "            \n",
    "read_raster(x_block_size, y_block_size)\n",
    "band = None\n",
    "ds = None\n",
    "dst_ds = None\n",
    "\n",
    "#print\"............... Done.................\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ox",
   "language": "python",
   "name": "ox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
